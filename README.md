
# üöÄ Curso Abrangente de Apache Flink: Dominando a Table API e SQL

Bem-vindo ao reposit√≥rio oficial do nosso curso completo sobre Apache Flink, com foco especial em sua poderosa Table API e SQL! Este material foi cuidadosamente elaborado para guiar voc√™, desenvolvedor ou engenheiro de dados, desde os conceitos fundamentais at√© t√≥picos avan√ßados no universo do processamento de dados em larga escala, tanto em *streaming* quanto em *batch*.

üáßüá∑ Este curso √© totalmente em **Portugu√™s do Brasil**.

[![Apache Flink](https://img.shields.io/badge/Apache%20Flink-1.19+-E6526F?logo=apacheflink&logoColor=white)](https://flink.apache.org/)
[![License](https://img.shields.io/badge/License-PENDING-blue)](#licen√ßa) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md) ---

## üéØ Sobre Este Curso

No mundo atual, a capacidade de processar e analisar vastos volumes de dados em tempo real √© crucial. O Apache Flink se destaca como uma plataforma l√≠der para esses desafios, e este curso tem como objetivo principal capacitar voc√™ a utilizar a **Table API e o SQL do Flink** de forma eficaz e produtiva.

Se voc√™ √© um desenvolvedor buscando construir aplica√ß√µes de processamento de dados robustas, um engenheiro de dados querendo dominar ETL de *streams* e an√°lises em tempo real, ou um analista que deseja aplicar SQL a *streams* de dados, este curso √© para voc√™!

**Ao final deste curso, voc√™ ser√° capaz de:**
* Entender profundamente o Apache Flink, sua arquitetura e seus casos de uso.
* Desenvolver aplica√ß√µes Flink usando a Table API e SQL para processamento de *streams* e *batch*.
* Implementar transforma√ß√µes de dados complexas, jun√ß√µes, agrega√ß√µes e trabalhar com janelas temporais.
* Estender o Flink com Fun√ß√µes Definidas pelo Usu√°rio (UDFs).
* Integrar o Flink com sistemas externos como Kafka, bancos de dados e sistemas de arquivos.
* Aplicar melhores pr√°ticas de otimiza√ß√£o, debugging e entender o funcionamento do Flink em ambientes gerenciados como o Confluent Cloud.

---

## üìö Estrutura do Curso (Vis√£o Geral dos M√≥dulos)

Este curso √© dividido em m√≥dulos progressivos, cada um focado em um aspecto espec√≠fico do Flink e sua Table API, culminando com um m√≥dulo b√¥nus que oferece uma vis√£o ainda mais ampla.

* **[Introdu√ß√£o do Curso](./chapters/module-00.md)**: Apresenta os objetivos, o p√∫blico-alvo e o roteiro completo do que voc√™ aprender√°. (Este arquivo pode conter o texto completo da introdu√ß√£o que elaboramos).

* **[M√≥dulo 1: Introdu√ß√£o ao Flink e √† Table API](./chapters/module-01.md)**: Uma introdu√ß√£o ao Apache Flink, suas capacidades de *streaming* e *batch*, e a configura√ß√£o do seu ambiente de desenvolvimento, com um olhar sobre a integra√ß√£o com o ecossistema Confluent.

* **[M√≥dulo 2: Conceitos Fundamentais da Table API](./chapters/module-02.md)**: Foca nos blocos de constru√ß√£o essenciais: o `TableEnvironment`, a cria√ß√£o de `Tables` a partir de diversas fontes (incluindo `DataStreams`), e as opera√ß√µes b√°sicas de manipula√ß√£o.

* **[M√≥dulo 3: Opera√ß√µes Relacionais](./chapters/module-03.md)**: Expande seu conhecimento para opera√ß√µes relacionais complexas, como diferentes tipos de `joins`, agrupamentos, agrega√ß√µes, opera√ß√µes de conjunto e ordena√ß√£o de resultados.

* **[M√≥dulo 4: Trabalhando com Tempo na Table API](./chapters/module-04.md)**: Um mergulho crucial no tratamento do tempo no Flink, cobrindo `event time`, `processing time`, `watermarks` e os diversos tipos de janelas (`tumbling`, `sliding`, `session`, `cumulative`).

* **[M√≥dulo 5: Fun√ß√µes Definidas pelo Usu√°rio (UDFs)](./chapters/module-05.md)**: Ensina como estender as funcionalidades nativas do Flink, implementando `scalar`, `table` e `aggregate functions` customizadas.

* **[M√≥dulo 6: Integra√ß√£o da Table API com SQL](./chapters/module-06.md)**: Explora a sinergia entre a Table API program√°tica e o poder declarativo do SQL, cobrindo o `Catalog`, execu√ß√£o de queries SQL, cria√ß√£o de `Views` e o uso em ambientes gerenciados.

* **[M√≥dulo 7: Conceitos Avan√ßados da Table API](./chapters/module-07.md)**: Aborda t√≥picos sofisticados como `Dynamic Tables`, `Continuous Queries`, `Temporal Tables` e `Temporal Joins` para enriquecimento de dados versionados, e `Upsert Streams`.

* **[M√≥dulo 8: Conectando a Sistemas Externos](./chapters/module-08.md)**: Foca na integra√ß√£o do Flink com o mundo exterior atrav√©s de `Connectors` e `Formats`, detalhando fontes e sinks comuns como FileSystem, Kafka e JDBC, incluindo o modelo no Confluent Cloud.

* **[M√≥dulo 9: Arquitetura, Melhores Pr√°ticas, Otimiza√ß√£o e Contribui√ß√£o](./chapters/module-09.md)**: Um m√≥dulo final abrangente que explora a arquitetura interna da Table API, como entender planos de execu√ß√£o, otimizar performance, depurar aplica√ß√µes, comparar Flink OSS com seu uso na Confluent Cloud, e como contribuir para o projeto Flink.

* **[M√≥dulo B√¥nus: Apache Flink - Uma Vis√£o Abrangente](./chapters/module-bonus.md)**: Oferece um mergulho profundo na hist√≥ria do Flink, sua arquitetura fundamental, a poderosa parceria com Apache Kafka, casos de uso ideais que destacam seu poder, mais detalhes sobre Flink gerenciado pela Confluent e um FAQ.

---

## üîß Pr√©-requisitos

Para o melhor aproveitamento deste curso, recomendamos:
* Familiaridade b√°sica com **Java** (os exemplos de c√≥digo s√£o nesta linguagem).
* Entendimento de conceitos **SQL**.
* Alguma experi√™ncia pr√©via com processamento de dados (*batch* ou *stream*) √© √∫til, mas n√£o estritamente obrigat√≥ria para os m√≥dulos iniciais.
* Um ambiente onde voc√™ possa instalar Java, Maven e seu IDE preferido para executar os exemplos.

---

## üìñ Como Usar Este Material

* **Siga a Ordem:** Os m√≥dulos foram desenhados para construir conhecimento progressivamente.
* **Pratique, Pratique, Pratique:** A melhor forma de aprender √© colocando a m√£o na massa! Execute os exemplos, modifique-os e tente os exerc√≠cios.
* **Consulte a Documenta√ß√£o Oficial:** Este curso √© um guia, mas a [documenta√ß√£o oficial do Apache Flink](https://flink.apache.org/docs/) √© a fonte definitiva.
* **Seja Curioso:** Explore, questione e divirta-se aprendendo!

---

## ‚úçÔ∏è Sobre os Autores

Este material de treinamento foi cuidadosamente elaborado atrav√©s de uma colabora√ß√£o especial:

* **Daniel Takabayashi:** Staff Solutions Engineer na Confluent, Daniel traz sua vasta experi√™ncia pr√°tica ajudando clientes a construir e otimizar solu√ß√µes de processamento de *streams* de dados em larga escala com Apache Flink e Apache Kafka. Sua expertise no ecossistema Confluent e seu profundo conhecimento das capacidades do Flink foram fundamentais para moldar o conte√∫do pr√°tico e relevante deste curso.

* **Gemini:** Seu amigo e assistente de IA do Google. Gemini colaborou na estrutura√ß√£o do conte√∫do, na gera√ß√£o de explica√ß√µes claras e exemplos, e na refina√ß√£o do material para garantir que seja did√°tico, completo e envolvente. Esta parceria buscou combinar o conhecimento t√©cnico especializado com a capacidade de apresentar informa√ß√µes complexas de forma acess√≠vel.

Esperamos que esta colabora√ß√£o resulte em uma experi√™ncia de aprendizado rica e proveitosa para voc√™!

---

## üôå Como Contribuir para Este Curso

Sua contribui√ß√£o √© muito bem-vinda! Se voc√™ encontrar erros, tiver sugest√µes de melhoria, novos exemplos, ou quiser ajudar de alguma forma, por favor:
1.  Abra uma **Issue** para discutir a mudan√ßa ou reportar o erro.
2.  Se desejar, fa√ßa um **Fork** do reposit√≥rio, crie um *branch* com suas modifica√ß√µes e submeta um **Pull Request**.

Consulte nosso arquivo `CONTRIBUTING.md` (se voc√™ criar um) para mais detalhes sobre como contribuir.

---

## üìú Licen√ßa

*(Adicione aqui a licen√ßa sob a qual voc√™ est√° disponibilizando este material. Ex: MIT, Apache 2.0, etc.)*

Exemplo:
Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo `LICENSE.md` (a ser criado) para detalhes.

---

Agradecemos seu interesse e esperamos que este curso seja um divisor de √°guas na sua jornada com Apache Flink!
```

Agora a se√ß√£o "Estrutura do Curso" tem links que devem funcionar se voc√™ organizar seus arquivos Markdown conforme o padr√£o `chapters/module-XX.md`. O link para a introdu√ß√£o tamb√©m foi adicionado como `chapters/module-00.md`.

Acho que com isso seu `README.md` est√° pronto para receber os leitores no GitHub!